---
description: The Crucial Role of Training Data in AI Development
---

# Background

Pundi AIFX is building an open, transparent, and decentralized AI data platform. Through decentralized and fair incentive mechanisms, we aim to continuously improve the quality and quantity of AI data while ensuring that a higher proportion of the fees paid by data users go directly to data providers. This way, the decentralized and open nature of blockchain can drive the AI revolution.

According to James Betker, a researcher at OpenAI, training data (rather than model design, architecture, or any other features) is the key to increasingly complex and powerful AI systems.&#x20;

`I’ve been at OpenAI for almost a year now. In that time, I’ve trained a lot of generative models. More than anyone really has any right to train. As I’ve spent these hours observing the effects of tweaking various model configurations and hyperparameters, one thing that has struck me is the similarities in between all the training runs.`

`It’s becoming awfully clear to me that these models are truly approximating their datasets to an incredible degree. What that means is not only that they learn what it means to be a dog or a cat, but the interstitial frequencies between distributions that don’t matter, like what photos humans are likely to take or words humans commonly write down.`

`What this manifests as is – trained on the same dataset for long enough, pretty much every model with enough weights and training time converges to the same point. Sufficiently large diffusion conv-unets produce the same images as ViT generators. AR sampling produces the same images as diffusion.`

`This is a surprising observation! It implies that model behavior is not determined by architecture, hyperparameters, or optimizer choices. It’s determined by your dataset, nothing else. Everything else is a means to an end in efficiently delivery compute to approximating that dataset.`

`Then, when you refer to “Lambda”, “ChatGPT”, “Bard”, or “Claude” then, it’s not the model weights that you are referring to. It’s the dataset.`

[https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/\
](https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/)

Meanwhile, large corporations' annual spending on data procurement is rapidly increasing from tens of billions to an estimated $300 to $500 billion, or even higher. Scale AI, a leading data provider in the AI industry, recently raised $1 billion with a valuation exceeding $14 billion and is expected to go public soon. In stark contrast to the success and admiration of leading AI companies, data providers like Scale AI often employ teams or subcontractors in developing countries, where workers are hired at extremely low costs and subjected to long hours without any benefits or job security.

Recognizing the importance, potential, and challenges in this domain, the Pundi team believes it can offer the world a decentralized data marketplace. This marketplace will protect workers' long-term interests and continuously improve data quality through market competition.

Here are some statistics for reference:

`OpenAI has spent hundreds of millions of dollars licensing content from news publishers, stock media libraries, and more to train its AI models — a budget far beyond that of most academic research groups, nonprofits, and startups.`

`Meta even considered acquiring publisher Simon & Schuster for the rights to e-book excerpts (ultimately, Simon & Schuster sold to private equity firm KKR for $1.62 billion in 2023).`

`Stock media library Shutterstock has signed deals with AI vendors ranging from $25 million to $50 million.`

`Reddit claims to have made hundreds of millions from licensing data to organizations such as Google and OpenAI.`\
